#  Neo4j å®Œæ•´æ•™ç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š

## ğŸ“‹ ç›®å½•

1. [Neo4j åŸºç¡€æ¦‚å¿µ](#1-neo4j-åŸºç¡€æ¦‚å¿µ)
2. [Cypher æŸ¥è¯¢è¯­è¨€è¯¦è§£](#2-cypher-æŸ¥è¯¢è¯­è¨€è¯¦è§£)
3. [Python æ•´åˆå¼€å‘](#3-python-æ•´åˆå¼€å‘)
4. [å®æˆ˜é¡¹ç›®æ¡ˆä¾‹](#4-å®æˆ˜é¡¹ç›®æ¡ˆä¾‹)
5. [æ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ](#5-æ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ)

---

## 1. Neo4j åŸºç¡€æ¦‚å¿µ

### 1.1 ä»€ä¹ˆæ˜¯å›¾æ•°æ®åº“ï¼Ÿ

å›¾æ•°æ®åº“æ˜¯ä¸€ç§ä¸“é—¨ç”¨äºå­˜å‚¨ã€ç®¡ç†å’ŒæŸ¥è¯¢å›¾ç»“æ„æ•°æ®çš„ NoSQL æ•°æ®åº“ã€‚

#### æ ¸å¿ƒæ¦‚å¿µå¯¹æ¯”

| ä¼ ç»Ÿå…³ç³»å‹æ•°æ®åº“ | Neo4j å›¾æ•°æ®åº“ |
|----------------|----------------|
| è¡¨ (Table) | æ ‡ç­¾ (Label) |
| è¡Œ (Row) | èŠ‚ç‚¹ (Node) |
| åˆ— (Column) | å±æ€§ (Property) |
| å¤–é”® (Foreign Key) | å…³ç³» (Relationship) |
| JOIN æ“ä½œ | éå† (Traversal) |

#### Neo4j æ•°æ®æ¨¡å‹

```python
# Neo4j çš„æ ¸å¿ƒç»„ä»¶
"""
èŠ‚ç‚¹ (Node):
  - ä»£è¡¨å®ä½“ï¼ˆå¦‚ï¼šç”¨æˆ·ã€äº§å“ã€æ–‡ç« ï¼‰
  - åŒ…å«å±æ€§ï¼ˆé”®å€¼å¯¹ï¼‰
  - å¯ä»¥æœ‰ä¸€ä¸ªæˆ–å¤šä¸ªæ ‡ç­¾

å…³ç³» (Relationship):
  - è¿æ¥ä¸¤ä¸ªèŠ‚ç‚¹
  - æœ‰æ–¹å‘ï¼ˆå¯ä»¥æœ‰åŒå‘å…³ç³»ï¼‰
  - å¿…é¡»æœ‰ç±»å‹
  - ä¹Ÿå¯ä»¥æœ‰å±æ€§

å±æ€§ (Property):
  - é”®å€¼å¯¹å­˜å‚¨
  - æ”¯æŒå„ç§æ•°æ®ç±»å‹
  - å¯ä»¥å­˜åœ¨äºèŠ‚ç‚¹å’Œå…³ç³»ä¸Š

æ ‡ç­¾ (Label):
  - èŠ‚ç‚¹çš„åˆ†ç±»
  - ç±»ä¼¼è¡¨å
  - ä¸€ä¸ªèŠ‚ç‚¹å¯ä»¥æœ‰å¤šä¸ªæ ‡ç­¾

è·¯å¾„ (Path):
  - èŠ‚ç‚¹å’Œå…³ç³»çš„åºåˆ—
  - è¡¨ç¤ºä¸¤ä¸ªèŠ‚ç‚¹é—´çš„è¿æ¥
"""
```

### 1.2 Neo4j æ¶æ„

```
Neo4j æ¶æ„ç»„ä»¶
â”œâ”€â”€ é©±åŠ¨ç¨‹åº (Driver)
â”‚   â”œâ”€â”€ åŒæ­¥é©±åŠ¨ (neo4j)
â”‚   â”œâ”€â”€ å¼‚æ­¥é©±åŠ¨ (neo4j[async])
â”‚   â””â”€â”€ å“åº”å¼é©±åŠ¨ (neo4j[reactive])
â”œâ”€â”€ ä¼šè¯ (Session)
â”‚   â”œâ”€â”€ è‡ªåŠ¨äº‹åŠ¡ç®¡ç†
â”‚   â”œâ”€â”€ è¯»å–ä¼šè¯
â”‚   â””â”€â”€ å†™å…¥ä¼šè¯
â”œâ”€â”€ äº‹åŠ¡ (Transaction)
â”‚   â”œâ”€â”€ ACID ç‰¹æ€§
â”‚   â”œâ”€â”€ æ˜¾å¼äº‹åŠ¡
â”‚   â””â”€â”€ è‡ªåŠ¨æäº¤äº‹åŠ¡
â””â”€â”€ è¿æ¥æ± 
    â”œâ”€â”€ è¿æ¥å¤ç”¨
    â”œâ”€â”€ è´Ÿè½½å‡è¡¡
    â””â”€â”€ æ•…éšœè½¬ç§»
```

---

## 2. Cypher æŸ¥è¯¢è¯­è¨€è¯¦è§£

Cypher æ˜¯ Neo4j çš„å£°æ˜å¼æŸ¥è¯¢è¯­è¨€ï¼Œç±»ä¼¼äº SQLï¼Œä½†ä¸“é—¨ä¸ºå›¾æ•°æ®è®¾è®¡ã€‚

### 2.1 åŸºç¡€è¯­æ³•ç»“æ„

#### 2.1.1 è¯»å–æŸ¥è¯¢ (READ)

```cypher
-- 1. åˆ›å»ºèŠ‚ç‚¹ (CREATE)
CREATE (p:Person {name: 'å¼ ä¸‰', age: 30, city: 'åŒ—äº¬'})

-- 2. æŸ¥è¯¢èŠ‚ç‚¹ (MATCH)
MATCH (p:Person {name: 'å¼ ä¸‰'})
RETURN p.name, p.age, p.city

-- 3. å¤šæ ‡ç­¾èŠ‚ç‚¹
MATCH (p:Person:Developer:PythonDeveloper)
RETURN p

-- 4. æ¡ä»¶æŸ¥è¯¢
MATCH (p:Person)
WHERE p.age > 25 AND p.city IN ['åŒ—äº¬', 'ä¸Šæµ·']
RETURN p.name, p.age, p.city

-- 5. æ­£åˆ™è¡¨è¾¾å¼æŸ¥è¯¢
MATCH (p:Person)
WHERE p.name =~ 'å¼ .*'
RETURN p.name

-- 6. å­—ç¬¦ä¸²å‡½æ•°
MATCH (p:Person)
RETURN p.name,
       size(p.name) AS name_length,
       toUpper(p.city) AS city_upper,
       substring(p.name, 0, 2) AS first_two_chars
```

#### 2.1.2 å…³ç³»æŸ¥è¯¢

```cypher
-- 1. åˆ›å»ºå…³ç³»
MATCH (a:Person {name: 'å¼ ä¸‰'}), (b:Person {name: 'æå››'})
CREATE (a)-[r:KNOWS {since: 2020, relationship: 'åŒäº‹'}]->(b)

-- 2. æŸ¥è¯¢å…³ç³»
MATCH (a:Person)-[r:KNOWS]->(b:Person)
RETURN a.name, type(r), properties(r), b.name

-- 3. å¯å˜é•¿åº¦è·¯å¾„æŸ¥è¯¢
MATCH (a:Person {name: 'å¼ ä¸‰'})-[:KNOWS*1..3]-(b:Person)
RETURN a.name, b.name

-- 4. æœ€çŸ­è·¯å¾„
MATCH (a:Person {name: 'å¼ ä¸‰'}), (b:Person {name: 'ç‹äº”'})
MATCH path = shortestPath((a)-[*]-(b))
RETURN path

-- 5. æ‰€æœ‰è·¯å¾„
MATCH (a:Person {name: 'å¼ ä¸‰'}), (b:Person {name: 'ç‹äº”'})
MATCH path = allShortestPaths((a)-[*]-(b))
RETURN path

-- 6. å…³ç³»ç±»å‹æŸ¥è¯¢
MATCH (a:Person)-[r]->(b:Person)
WHERE type(r) STARTS WITH 'KNOW'
RETURN a.name, type(r), b.name

-- 7. åŒå‘å…³ç³»æŸ¥è¯¢
MATCH (a:Person)-[r:KNOWS]-(b:Person)
RETURN a.name, r.since, b.name
```

#### 2.1.3 èšåˆå‡½æ•°

```cypher
-- 1. åŸºç¡€èšåˆ
MATCH (p:Person)
RETURN count(p) AS total_persons,
       avg(p.age) AS avg_age,
       min(p.age) AS min_age,
       max(p.age) AS max_age,
       sum(p.age) AS total_age

-- 2. åˆ†ç»„èšåˆ
MATCH (p:Person)
RETURN p.city,
       count(p) AS person_count,
       avg(p.age) AS avg_age
ORDER BY person_count DESC

-- 3. å»é‡è®¡æ•°
MATCH (p:Person)
RETURN count(DISTINCT p.city) AS unique_cities

-- 4. æ”¶é›†èšåˆ
MATCH (p:Person)
RETURN p.city,
       collect(p.name) AS names,
       collect(DISTINCT p.name) AS unique_names

-- 5. ç™¾åˆ†ä½è®¡ç®—
MATCH (p:Person)
RETURN percentileCont(p.age, 0.5) AS median_age,
       percentileDisc(p.age, 0.95) AS percentile_95

-- 6. æ ‡å‡†å·®å’Œæ–¹å·®
MATCH (p:Person)
RETURN stdev(p.age) AS std_deviation,
       stdevp(p.age) AS population_std_dev
```

### 2.2 é«˜çº§æŸ¥è¯¢æŠ€å·§

#### 2.2.1 WITH å­å¥

```cypher
-- 1. é“¾å¼æŸ¥è¯¢
MATCH (p:Person)
WHERE p.age > 25
WITH p
ORDER BY p.age DESC
LIMIT 3
MATCH (p)-[:KNOWS]-(friend)
RETURN p.name AS person, collect(friend.name) AS friends

-- 2. å˜é‡ä¼ é€’
MATCH (p:Person)
WITH p.name AS name, toUpper(p.name) AS upper_name
RETURN name, upper_name

-- 3. èšåˆåç»§ç»­æŸ¥è¯¢
MATCH (p:Person)
WITH p.city AS city, count(p) AS count
WHERE count > 2
MATCH (people:Person {city: city})
RETURN city, count, collect(people.name) AS names
```

#### 2.2.2 æ¡ä»¶è¡¨è¾¾å¼

```cypher
-- 1. CASE è¡¨è¾¾å¼
MATCH (p:Person)
RETURN p.name,
       CASE
           WHEN p.age < 20 THEN 'å¹´è½»'
           WHEN p.age < 35 THEN 'ä¸­å¹´'
           ELSE 'æˆç†Ÿ'
       END AS age_group

-- 2. COALESCE å‡½æ•°
MATCH (p:Person)
RETURN p.name,
       coalesce(p.nickname, p.name) AS display_name

-- 3. ä¸‰å…ƒæ“ä½œç¬¦
MATCH (p:Person)
RETURN p.name,
       (p.age > 30 ? 'èµ„æ·±' : 'åˆçº§') AS experience_level
```

#### 2.2.3 åˆ—è¡¨æ“ä½œ

```cypher
-- 1. åˆ›å»ºåˆ—è¡¨
RETURN [1, 2, 3] AS numbers

-- 2. åˆ—è¡¨å‡½æ•°
MATCH (p:Person {name: 'å¼ ä¸‰'})
RETURN size(p.skills) AS skill_count,
       p.skills[0] AS first_skill,
       p.skills[-1] AS last_skill,
       reverse(p.skills) AS reversed_skills

-- 3. åˆ—è¡¨æ¨å¯¼
MATCH (p:Person)
RETURN [x IN p.skills WHERE size(x) > 4] AS long_skills

-- 4. åˆ—è¡¨è¿‡æ»¤
MATCH (p:Person)
RETURN filter(x IN p.skills WHERE x CONTAINS 'Python') AS python_skills

-- 5. åˆ—è¡¨è½¬æ¢
MATCH (p:Person)
RETURN [x IN p.skills | toUpper(x)] AS upper_skills

-- 6. åˆ—è¡¨èšåˆ
MATCH (p:Person)
RETURN reduce(total = 0, n IN [1, 2, 3, 4, 5] | total + n) AS sum
```

#### 2.2.4 å­—ç¬¦ä¸²æ“ä½œ

```cypher
-- 1. å­—ç¬¦ä¸²å‡½æ•°
RETURN 'Neo4j' AS db,
       size('Neo4j') AS length,
       toUpper('neo4j') AS upper,
       toLower('NEO4J') AS lower,
       reverse('Neo4j') AS reversed

-- 2. å­—ç¬¦ä¸²æ›¿æ¢
WITH 'Hello World' AS text
RETURN replace(text, 'World', 'Neo4j') AS replaced

-- 3. å­—ç¬¦ä¸²åˆ†å‰²å’Œè¿æ¥
WITH 'Python,Java,JavaScript' AS languages
RETURN split(languages, ',') AS lang_list,
       join(['Python', 'Neo4j'], ' + ') AS combined

-- 4. å­å­—ç¬¦ä¸²
WITH 'Neo4j Graph Database' AS text
RETURN substring(text, 0, 6) AS neo4j,
       left(text, 6) AS left_part,
       right(text, 8) AS right_part
```

### 2.3 æ•°æ®ä¿®æ”¹æ“ä½œ

#### 2.3.1 åˆ›å»ºå’Œæ›´æ–°

```cypher
-- 1. MERGE - åˆ›å»ºæˆ–æ›´æ–°
MERGE (p:Person {name: 'å¼ ä¸‰'})
ON CREATE SET p.age = 30, p.created = timestamp()
ON MATCH SET p.last_seen = timestamp()
RETURN p

-- 2. SET - æ›´æ–°å±æ€§
MATCH (p:Person {name: 'å¼ ä¸‰'})
SET p.age = 31,
    p.email = 'zhangsan@example.com',
    p.tags = ['developer', 'python']

-- 3. SET - åŠ¨æ€å±æ€§æ›´æ–°
MATCH (p:Person {name: 'å¼ ä¸‰'})
SET p += {city: 'åŒ—äº¬', status: 'active'}

-- 4. SET - åˆ—è¡¨æ“ä½œ
MATCH (p:Person {name: 'å¼ ä¸‰'})
SET p.skills = p.skills + ['Neo4j'],  -- æ·»åŠ åˆ°åˆ—è¡¨
    p.hobbies = p.hobbies - ['æ¸¸æˆ']   -- ä»åˆ—è¡¨ç§»é™¤

-- 5. INCREMENT - æ•°å€¼é€’å¢
MATCH (p:Person {name: 'å¼ ä¸‰'})
SET p.login_count = coalesce(p.login_count, 0) + 1
```

#### 2.3.2 åˆ é™¤æ“ä½œ

```cypher
-- 1. åˆ é™¤å±æ€§
MATCH (p:Person {name: 'å¼ ä¸‰'})
REMOVE p.email, p.status

-- 2. åˆ é™¤æ ‡ç­¾
MATCH (p:Person {name: 'å¼ ä¸‰'})
REMOVE p:Developer

-- 3. åˆ é™¤å…³ç³»
MATCH (p:Person {name: 'å¼ ä¸‰'})-[r:KNOWS]-()
DELETE r

-- 4. åˆ é™¤èŠ‚ç‚¹ï¼ˆéœ€è¦å…ˆåˆ é™¤æ‰€æœ‰å…³ç³»ï¼‰
MATCH (p:Person {name: 'å¼ ä¸‰'})
DETACH DELETE p

-- 5. æ‰¹é‡åˆ é™¤
MATCH (p:Person)
WHERE p.last_seen < timestamp() - duration({days: 365})
DETACH DELETE p
```

### 2.4 äº‹åŠ¡ç®¡ç†

```cypher
-- 1. è‡ªåŠ¨äº‹åŠ¡ï¼ˆæ¯ä¸ªæŸ¥è¯¢è‡ªåŠ¨æäº¤ï¼‰
MATCH (p:Person {name: 'å¼ ä¸‰'})
SET p.last_login = timestamp()

-- 2. æ˜¾å¼äº‹åŠ¡ï¼ˆåœ¨å®¢æˆ·ç«¯ä»£ç ä¸­ï¼‰
-- BEGIN
MATCH (p:Person {name: 'å¼ ä¸‰'}) SET p.balance = p.balance - 100
MATCH (p:Person {name: 'æå››'}) SET p.balance = p.balance + 100
-- COMMIT

-- 3. äº‹åŠ¡å‡½æ•°ï¼ˆåœ¨ Python ä¸­ï¼‰
WITH transaction(tx) AS tx.begin_transaction()
tx.run("MATCH (p:Person {name: $name}) SET p.balance = $balance",
       name="å¼ ä¸‰", balance=1000)
tx.commit()
```

---

## 3. Python æ•´åˆå¼€å‘

### 3.1 å®‰è£…å’Œé…ç½®

```python
# å®‰è£… Neo4j Python é©±åŠ¨
pip install neo4j

# å®‰è£…å¯é€‰ä¾èµ–
pip install pandas          # æ•°æ®åˆ†æ
pip install numpy           # æ•°å€¼è®¡ç®—
pip install matplotlib       # æ•°æ®å¯è§†åŒ–
pip install networkx         # å›¾åˆ†æ
pip install py2neo          # å¦ä¸€ä¸ª Neo4j é©±åŠ¨
```

### 3.2 åŸºç¡€è¿æ¥å’ŒæŸ¥è¯¢

```python
from neo4j import GraphDatabase
import pandas as pd
from typing import List, Dict, Optional, Any

# è¿æ¥é…ç½®
URI = "bolt://localhost:7687"
AUTH = ("neo4j", "password123")

class Neo4jConnection:
    """Neo4j è¿æ¥ç®¡ç†ç±»"""

    def __init__(self, uri: str, auth: tuple):
        self.driver = GraphDatabase.driver(uri, auth=auth)

    def close(self):
        """å…³é—­è¿æ¥"""
        if self.driver:
            self.driver.close()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()

    def execute_query(self, query: str, **params) -> pd.DataFrame:
        """æ‰§è¡ŒæŸ¥è¯¢å¹¶è¿”å› DataFrame"""
        with self.driver.session() as session:
            result = session.run(query, **params)
            return pd.DataFrame([dict(record) for record in result])

# ä½¿ç”¨ç¤ºä¾‹
with Neo4jConnection(URI, AUTH) as conn:
    # ç®€å•æŸ¥è¯¢
    df = conn.execute_query("MATCH (p:Person) RETURN p.name, p.age LIMIT 5")
    print(df)

    # å‚æ•°åŒ–æŸ¥è¯¢
    df = conn.execute_query(
        "MATCH (p:Person) WHERE p.age > $age RETURN p.name",
        age=30
    )
    print(df)
```

### 3.3 ä¼šè¯ç®¡ç†

```python
from neo4j import GraphDatabase, Session, READ, WRITE

class Neo4jSessionManager:
    """Neo4j ä¼šè¯ç®¡ç†"""

    def __init__(self, uri: str, auth: tuple):
        self.driver = GraphDatabase.driver(uri, auth=auth)

    def read_session(self, database: str = "neo4j") -> Session:
        """åˆ›å»ºè¯»å–ä¼šè¯"""
        return self.driver.session(database=database, default_access_mode=READ)

    def write_session(self, database: str = "neo4j") -> Session:
        """åˆ›å»ºå†™å…¥ä¼šè¯"""
        return self.driver.session(database=database, default_access_mode=WRITE)

    def execute_read(self, query: str, **params) -> List[Dict]:
        """æ‰§è¡Œè¯»å–æ“ä½œ"""
        with self.read_session() as session:
            result = session.run(query, **params)
            return [dict(record) for record in result]

    def execute_write(self, query: str, **params) -> List[Dict]:
        """æ‰§è¡Œå†™å…¥æ“ä½œ"""
        with self.write_session() as session:
            result = session.run(query, **params)
            return [dict(record) for record in result]
```

### 3.4 äº‹åŠ¡å¤„ç†

```python
from neo4j import GraphDatabase, Transaction

class Neo4jTransactionManager:
    """Neo4j äº‹åŠ¡ç®¡ç†"""

    def __init__(self, driver):
        self.driver = driver

    def transactional_example(self):
        """äº‹åŠ¡ç¤ºä¾‹ï¼šè½¬è´¦æ“ä½œ"""
        def transfer_funds(tx: Transaction, from_account: str, to_account: str, amount: float):
            """è½¬è´¦å‡½æ•°"""
            # æ£€æŸ¥ä½™é¢
            result = tx.run(
                "MATCH (a:Account {id: $id}) RETURN a.balance",
                id=from_account
            )
            balance = result.single()["a.balance"]

            if balance < amount:
                raise ValueError("ä½™é¢ä¸è¶³")

            # æ‰§è¡Œè½¬è´¦
            tx.run(
                "MATCH (a:Account {id: $id}) SET a.balance = a.balance - $amount",
                id=from_account, amount=amount
            )
            tx.run(
                "MATCH (a:Account {id: $id}) SET a.balance = a.balance + $amount",
                id=to_account, amount=amount
            )

        # æ‰§è¡Œäº‹åŠ¡
        with self.driver.session() as session:
            try:
                session.write_transaction(
                    transfer_funds,
                    from_account="acc1",
                    to_account="acc2",
                    amount=100.0
                )
                print("è½¬è´¦æˆåŠŸ")
            except Exception as e:
                print(f"è½¬è´¦å¤±è´¥: {e}")

    def batch_operations(self):
        """æ‰¹é‡æ“ä½œ"""
        def create_multiple_nodes(tx: Transaction, nodes_data: List[Dict]):
            """æ‰¹é‡åˆ›å»ºèŠ‚ç‚¹"""
            query = """
            UNWIND $nodes AS node_data
            CREATE (n:Node {properties: node_data})
            """
            tx.run(query, nodes=nodes_data)

        # å‡†å¤‡æ•°æ®
        nodes = [
            {"name": f"Node{i}", "value": i * 10}
            for i in range(1000)
        ]

        # æ‰§è¡Œæ‰¹é‡æ“ä½œ
        with self.driver.session() as session:
            session.write_transaction(create_multiple_nodes, nodes)
            print(f"æ‰¹é‡åˆ›å»ºäº† {len(nodes)} ä¸ªèŠ‚ç‚¹")
```

### 3.5 å¼‚æ­¥ç¼–ç¨‹

```python
import asyncio
from neo4j import AsyncGraphDatabase, AsyncSession
from typing import AsyncGenerator

class AsyncNeo4jClient:
    """å¼‚æ­¥ Neo4j å®¢æˆ·ç«¯"""

    def __init__(self, uri: str, auth: tuple):
        self.driver = AsyncGraphDatabase.driver(uri, auth=auth)

    async def close(self):
        """å…³é—­å¼‚æ­¥è¿æ¥"""
        await self.driver.close()

    async def execute_query(self, query: str, **params) -> List[Dict]:
        """å¼‚æ­¥æ‰§è¡ŒæŸ¥è¯¢"""
        async with self.driver.session() as session:
            result = await session.run(query, **params)
            return [dict(record) async for record in result]

    async def stream_results(self, query: str, **params) -> AsyncGenerator[Dict, None]:
        """å¼‚æ­¥æµå¼å¤„ç†ç»“æœ"""
        async with self.driver.session() as session:
            result = await session.run(query, **params)
            async for record in result:
                yield dict(record)

# å¼‚æ­¥ä½¿ç”¨ç¤ºä¾‹
async def async_example():
    client = AsyncNeo4jClient(URI, AUTH)
    try:
        # æ‰§è¡ŒæŸ¥è¯¢
        results = await client.execute_query(
            "MATCH (p:Person) RETURN p.name, p.age LIMIT 10"
        )
        print("å¼‚æ­¥æŸ¥è¯¢ç»“æœ:", results)

        # æµå¼å¤„ç†
        async for record in client.stream_results(
            "MATCH (p:Person) RETURN p.name"
        ):
            print("æµå¼è®°å½•:", record)
    finally:
        await client.close()

# è¿è¡Œå¼‚æ­¥ç¤ºä¾‹
# asyncio.run(async_example())
```

### 3.6 é«˜çº§åŠŸèƒ½

```python
import time
from neo4j import GraphDatabase, ExponentialBackoff, Retryable

class AdvancedNeo4jOperations:
    """é«˜çº§ Neo4j æ“ä½œ"""

    def __init__(self, driver):
        self.driver = driver
        self.retry_policy = ExponentialBackoff(
            initial_retry_delay=0.1,
            multiplier=2.0,
            jitter_factor=0.1
        )

    def execute_with_retry(self, query: str, max_retries: int = 3, **params):
        """å¸¦é‡è¯•æœºåˆ¶çš„æŸ¥è¯¢æ‰§è¡Œ"""
        last_exception = None
        for attempt in range(max_retries):
            try:
                with self.driver.session() as session:
                    result = session.run(query, **params)
                    return [dict(record) for record in result]
            except Exception as e:
                if isinstance(e, Retryable) and attempt < max_retries - 1:
                    last_exception = e
                    delay = self.retry_policy.next_delay(attempt)
                    time.sleep(delay)
                    continue
                else:
                    raise e
        raise last_exception

    def explain_query(self, query: str, **params) -> List[Dict]:
        """æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’åˆ†æ"""
        explain_query = f"EXPLAIN {query}"
        with self.driver.session() as session:
            result = session.run(explain_query, **params)
            return [dict(record) for record in result]

    def profile_query(self, query: str, **params) -> List[Dict]:
        """æŸ¥è¯¢æ€§èƒ½åˆ†æ"""
        profile_query = f"PROFILE {query}"
        with self.driver.session() as session:
            result = session.run(profile_query, **params)
            return [dict(record) for record in result]

    def bulk_import_with_apoc(self, file_path: str, label: str):
        """ä½¿ç”¨ APOC æ’ä»¶æ‰¹é‡å¯¼å…¥"""
        query = f"""
        CALL apoc.import.csv('{file_path}', {{header: true}})
        YIELD map
        CREATE (n:{label} $map)
        RETURN count(n) as imported_count
        """
        with self.driver.session() as session:
            result = session.run(query)
            return result.single()["imported_count"]

    def graph_algorithms(self):
        """å›¾ç®—æ³•ç¤ºä¾‹"""
        with self.driver.session() as session:
            # PageRank ç®—æ³•
            pagerank_query = """
            CALL gds.pageRank.stream('myGraph')
            YIELD nodeId, score
            RETURN gds.util.asNode(nodeId).name AS name, score
            ORDER BY score DESC
            LIMIT 10
            """
            pagerank_results = session.run(pagerank_query)

            # ç¤¾åŒºæ£€æµ‹
            community_query = """
            CALL gds.louvain.stream('myGraph')
            YIELD nodeId, communityId
            RETURN communityId, collect(gds.util.asNode(nodeId).name) AS members
            ORDER BY communityId
            """
            community_results = session.run(community_query)

            # æœ€çŸ­è·¯å¾„
            shortest_path_query = """
            CALL gds.shortestPath.dijkstra.stream('myGraph', {
                sourceNode: gds.util.asNode('Person', 'å¼ ä¸‰'),
                targetNode: gds.util.asNode('Person', 'æå››'),
                relationshipWeightProperty: 'weight'
            })
            YIELD nodeIds, totalCost
            RETURN [gds.util.asNode(id).name for id in nodeIds] AS path, totalCost
            """
            path_results = session.run(shortest_path_query)

            return {
                'pagerank': [dict(r) for r in pagerank_results],
                'communities': [dict(r) for r in community_results],
                'shortest_path': [dict(r) for r in path_results]
            }
```

### 3.7 ORM é£æ ¼å°è£…

```python
from dataclasses import dataclass
from typing import ClassVar, TypeVar, Generic, Type
from neo4j import GraphDatabase, Driver

T = TypeVar('T', bound='Neo4jModel')

@dataclass
class Neo4jModel:
    """Neo4j æ¨¡å‹åŸºç±»"""
    _labels: ClassVar[tuple] = ()
    _driver: ClassVar[Driver] = None

    @classmethod
    def set_driver(cls, driver: Driver):
        """è®¾ç½®æ•°æ®åº“é©±åŠ¨"""
        cls._driver = driver

    @classmethod
    def get_label_string(cls) -> str:
        """è·å–æ ‡ç­¾å­—ç¬¦ä¸²"""
        return ':'.join(cls._labels)

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            k: v for k, v in self.__dict__.items()
            if not k.startswith('_')
        }

    def create(self) -> Dict:
        """åˆ›å»ºèŠ‚ç‚¹"""
        labels = self.get_label_string()
        props = ', '.join([f'{k}: ${k}' for k in self.to_dict().keys()])
        query = f"CREATE (n:{labels} {{{props}}) RETURN n"

        with self._driver.session() as session:
            result = session.run(query, **self.to_dict())
            return dict(result.single())

    def save(self) -> Dict:
        """ä¿å­˜èŠ‚ç‚¹ï¼ˆMERGEï¼‰"""
        labels = self.get_label_string()
        props = self.to_dict()

        # å‡è®¾æœ‰ä¸€ä¸ªå”¯ä¸€æ ‡è¯†ç¬¦
        id_field = getattr(self, '_id_field', 'id')
        if hasattr(self, id_field):
            query = f"""
            MERGE (n:{labels} {{{id_field}: ${id_field}}})
            SET n += $props
            RETURN n
            """
            with self._driver.session() as session:
                result = session.run(query, id_field=getattr(self, id_field), **props)
                return dict(result.single())

    @classmethod
    def find_by_id(cls: Type[T], value: Any) -> Optional[T]:
        """æ ¹æ® ID æŸ¥æ‰¾"""
        id_field = getattr(cls, '_id_field', 'id')
        labels = cls.get_label_string()
        query = f"MATCH (n:{labels} {{{id_field}: $value}}) RETURN n"

        with cls._driver.session() as session:
            result = session.run(query, value=value)
            record = result.single()
            if record:
                return cls.from_record(record['n'])
        return None

    @classmethod
    def from_record(cls: Type[T], record) -> T:
        """ä» Neo4j è®°å½•åˆ›å»ºå®ä¾‹"""
        return cls(**dict(record))

# ä½¿ç”¨ç¤ºä¾‹
@dataclass
class Person(Neo4jModel):
    """ç”¨æˆ·æ¨¡å‹"""
    name: str
    age: int
    email: str
    city: str
    _labels: ClassVar[tuple] = ('Person', 'User')
    _id_field: ClassVar[str] = 'email'

# åˆå§‹åŒ–
driver = GraphDatabase.driver(URI, AUTH=AUTH)
Person.set_driver(driver)

# åˆ›å»ºç”¨æˆ·
person = Person(name="å¼ ä¸‰", age=30, email="zhangsan@example.com", city="åŒ—äº¬")
person.create()

# æŸ¥æ‰¾ç”¨æˆ·
found = Person.find_by_id("zhangsan@example.com")
if found:
    print(f"æ‰¾åˆ°ç”¨æˆ·: {found.name}")
```

---

## 4. å®æˆ˜é¡¹ç›®æ¡ˆä¾‹

### 4.1 ç¤¾äº¤ç½‘ç»œåˆ†æç³»ç»Ÿ

```python
from neo4j import GraphDatabase
import networkx as nx
import matplotlib.pyplot as plt
from typing import List, Dict, Tuple

class SocialNetworkAnalyzer:
    """ç¤¾äº¤ç½‘ç»œåˆ†æç³»ç»Ÿ"""

    def __init__(self, uri: str, auth: tuple):
        self.driver = GraphDatabase.driver(uri, auth=auth)
        self.graph = None

    def build_network_graph(self, max_nodes: int = 100):
        """æ„å»º NetworkX å›¾"""
        query = """
        MATCH (p:Person)-[r:FRIENDS_WITH]-(friend:Person)
        RETURN p.name AS source, friend.name AS target, r.strength AS weight
        LIMIT $limit
        """

        with self.driver.session() as session:
            result = session.run(query, limit=max_nodes)
            edges = [
                (record['source'], record['target'], record['weight'])
                for record in result
            ]

        # åˆ›å»º NetworkX å›¾
        self.graph = nx.DiGraph()
        for source, target, weight in edges:
            self.graph.add_edge(source, target, weight=weight)

        return self.graph

    def analyze_network_metrics(self):
        """åˆ†æç½‘ç»œæŒ‡æ ‡"""
        if not self.graph:
            self.build_network_graph()

        metrics = {
            'node_count': self.graph.number_of_nodes(),
            'edge_count': self.graph.number_of_edges(),
            'density': nx.density(self.graph),
            'avg_clustering': nx.average_clustering(self.graph.to_undirected()),
            'diameter': nx.diameter(self.graph) if nx.is_connected(self.graph) else None
        }

        # è®¡ç®—ä¸­å¿ƒæ€§æŒ‡æ ‡
        degree_centrality = nx.degree_centrality(self.graph)
        betweenness_centrality = nx.betweenness_centrality(self.graph)
        closeness_centrality = nx.closeness_centrality(self.graph)

        metrics['top_degree'] = sorted(
            degree_centrality.items(), key=lambda x: x[1], reverse=True
        )[:5]
        metrics['top_betweenness'] = sorted(
            betweenness_centrality.items(), key=lambda x: x[1], reverse=True
        )[:5]

        return metrics

    def detect_communities(self):
        """ç¤¾åŒºæ£€æµ‹"""
        if not self.graph:
            self.build_network_graph()

        # ä½¿ç”¨ Louvain ç®—æ³•æ£€æµ‹ç¤¾åŒº
        import community as community_louvain

        # è½¬æ¢ä¸ºæ— å‘å›¾
        undirected = self.graph.to_undirected()
        partition = community_louvain.best_partition(undirected)

        # æŒ‰ç¤¾åŒºåˆ†ç»„
        communities = {}
        for node, comm_id in partition.items():
            if comm_id not in communities:
                communities[comm_id] = []
            communities[comm_id].append(node)

        return communities

    def visualize_network(self, layout='spring', figsize=(12, 8)):
        """å¯è§†åŒ–ç½‘ç»œå›¾"""
        if not self.graph:
            self.build_network_graph()

        plt.figure(figsize=figsize)

        # é€‰æ‹©å¸ƒå±€
        if layout == 'spring':
            pos = nx.spring_layout(self.graph, k=0.5, iterations=50)
        elif layout == 'circular':
            pos = nx.circular_layout(self.graph)
        elif layout == 'random':
            pos = nx.random_layout(self.graph)
        else:
            pos = nx.spring_layout(self.graph)

        # ç»˜åˆ¶èŠ‚ç‚¹
        node_degree = dict(self.graph.degree())
        node_sizes = [v * 50 for v in node_degree.values()]

        nx.draw_networkx_nodes(
            self.graph, pos,
            node_size=node_sizes,
            node_color='lightblue',
            alpha=0.7
        )

        # ç»˜åˆ¶è¾¹
        edges = self.graph.edges()
        edge_weights = [self.graph[u][v]['weight'] for u, v in edges]

        nx.draw_networkx_edges(
            self.graph, pos,
            width=[w * 0.5 for w in edge_weights],
            alpha=0.5,
            edge_color='gray'
        )

        # ç»˜åˆ¶æ ‡ç­¾
        nx.draw_networkx_labels(
            self.graph, pos,
            font_size=8,
            font_family='SimHei'
        )

        plt.title("ç¤¾äº¤ç½‘ç»œå›¾", fontsize=14, fontfamily='SimHei')
        plt.axis('off')
        plt.tight_layout()
        plt.show()

    def recommend_friends(self, user_name: str, method: str = 'common_friends'):
        """æ¨èå¥½å‹"""
        if method == 'common_friends':
            query = """
            MATCH (u:Person {name: $user})-[:FRIENDS_WITH]-(friend)-[:FRIENDS_WITH]-(potential:Person)
            WHERE NOT (u)-[:FRIENDS_WITH]-(potential) AND u <> potential
            WITH potential, count(DISTINCT friend) AS common_friends_count,
                 collect(DISTINCT friend.name) AS common_friends
            RETURN potential.name AS recommended,
                   common_friends_count,
                   common_friends
            ORDER BY common_friends_count DESC
            LIMIT 5
            """
        elif method == 'preferential_attachment':
            query = """
            MATCH (u:Person {name: $user})
            MATCH (potential:Person)
            WHERE NOT (u)-[:FRIENDS_WITH]-(potential) AND u <> potential
            WITH u, potential,
                 (size((u)-[:FRIENDS_WITH]-())) * (size((potential)-[:FRIENDS_WITH]-())) AS score
            RETURN potential.name AS recommended, score
            ORDER BY score DESC
            LIMIT 5
            """

        with self.driver.session() as session:
            result = session.run(query, user=user_name)
            return [dict(record) for record in result]

# ä½¿ç”¨ç¤ºä¾‹
# analyzer = SocialNetworkAnalyzer(URI, AUTH)
# analyzer.build_network_graph()
# metrics = analyzer.analyze_network_metrics()
# print("ç½‘ç»œæŒ‡æ ‡:", metrics)
# analyzer.visualize_network()
# recommendations = analyzer.recommend_friends("å¼ ä¸‰")
# print("æ¨èå¥½å‹:", recommendations)
```

### 4.2 çŸ¥è¯†å›¾è°±æ„å»º

```python
from neo4j import GraphDatabase
import json
from typing import List, Dict, Any

class KnowledgeGraphBuilder:
    """çŸ¥è¯†å›¾è°±æ„å»ºå™¨"""

    def __init__(self, uri: str, auth: tuple):
        self.driver = GraphDatabase.driver(uri, auth=auth)

    def create_schema(self):
        """åˆ›å»ºçŸ¥è¯†å›¾è°±æ¨¡å¼"""
        constraints = [
            # å®ä½“çº¦æŸ
            "CREATE CONSTRAINT entity_id_unique IF NOT EXISTS FOR (e:Entity) REQUIRE e.id IS UNIQUE",
            "CREATE constraint concept_name_unique IF NOT EXISTS FOR (c:Concept) REQUIRE c.name IS UNIQUE",

            # å…³ç³»çº¦æŸ
            "CREATE CONSTRAINT relation_id_unique IF NOT EXISTS FOR ()-[r:RELATION]-() REQUIRE r.id IS UNIQUE"
        ]

        indexes = [
            # å®ä½“ç´¢å¼•
            "CREATE INDEX entity_type_index IF NOT EXISTS FOR (e:Entity) ON (e.type)",
            "CREATE INDEX entity_name_index IF NOT EXISTS FOR (e:Entity) ON (e.name)",

            # æ¦‚å¿µç´¢å¼•
            "CREATE INDEX concept_category_index IF NOT EXISTS FOR (c:Concept) ON (e.category)",

            # å…³ç³»ç´¢å¼•
            "CREATE INDEX relation_type_index IF NOT EXISTS FOR ()-[r:RELATION]-() ON (r.type)"
        ]

        with self.driver.session() as session:
            for constraint in constraints:
                try:
                    session.run(constraint)
                    print(f"çº¦æŸåˆ›å»ºæˆåŠŸ: {constraint}")
                except Exception as e:
                    print(f"çº¦æŸå¯èƒ½å·²å­˜åœ¨: {e}")

            for index in indexes:
                try:
                    session.run(index)
                    print(f"ç´¢å¼•åˆ›å»ºæˆåŠŸ: {index}")
                except Exception as e:
                    print(f"ç´¢å¼•å¯èƒ½å·²å­˜åœ¨: {e}")

    def import_from_json(self, json_file: str):
        """ä» JSON æ–‡ä»¶å¯¼å…¥çŸ¥è¯†å›¾è°±"""
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        with self.driver.session() as session:
            with session.begin_transaction() as tx:
                try:
                    # åˆ›å»ºå®ä½“
                    if 'entities' in data:
                        for entity in data['entities']:
                            tx.run(
                                """
                                MERGE (e:Entity {id: $id})
                                SET e.name = $name,
                                    e.type = $type,
                                    e.properties = $properties
                                """,
                                **entity
                            )

                    # åˆ›å»ºæ¦‚å¿µ
                    if 'concepts' in data:
                        for concept in data['concepts']:
                            tx.run(
                                """
                                MERGE (c:Concept {name: $name})
                                SET c.category = $category,
                                    c.description = $description
                                """,
                                **concept
                            )

                    # åˆ›å»ºå…³ç³»
                    if 'relations' in data:
                        for relation in data['relations']:
                            # æ ¹æ®å…³ç³»ç±»å‹å¤„ç†ä¸åŒçš„å…³ç³»
                            if relation.get('type') == 'instanceOf':
                                tx.run(
                                    """
                                    MATCH (e:Entity {id: $source}), (c:Concept {name: $target})
                                    MERGE (e)-[r:INSTANCE_OF]->(c)
                                    SET r.confidence = $confidence
                                    """,
                                    source=relation['source'],
                                    target=relation['target'],
                                    confidence=relation.get('confidence', 1.0)
                                )
                            elif relation.get('type') == 'relatedTo':
                                tx.run(
                                    """
                                    MATCH (e1:Entity {id: $source}), (e2:Entity {id: $target})
                                    MERGE (e1)-[r:RELATED_TO]->(e2)
                                    SET r.relation_type = $relation_type,
                                        r.confidence = $confidence
                                    """,
                                    source=relation['source'],
                                    target=relation['target'],
                                    relation_type=relation.get('relation_type', 'general'),
                                    confidence=relation.get('confidence', 1.0)
                                )

                    tx.commit()
                    print(f"æˆåŠŸä» {json_file} å¯¼å…¥çŸ¥è¯†å›¾è°±æ•°æ®")
                except Exception as e:
                    tx.rollback()
                    print(f"å¯¼å…¥å¤±è´¥: {e}")

    def extract_entities_from_text(self, text: str):
        """ä»æ–‡æœ¬ä¸­æå–å®ä½“"""
        # è¿™é‡Œå¯ä»¥é›†æˆ NLP åº“ï¼Œå¦‚ spaCy
        # ç®€åŒ–ç¤ºä¾‹ï¼šåŸºäºè§„åˆ™æå–
        entities = []

        # æå–äººåï¼ˆç®€åŒ–ï¼‰
        import re
        person_pattern = r'([A-Z][a-z]+ [A-Z][a-z]+)'
        persons = re.findall(person_pattern, text)
        for person in persons:
            entities.append({
                'id': f"person_{hash(person)}",
                'name': person,
                'type': 'Person',
                'properties': {'source': 'text_extraction'}
            })

        # æå–åœ°ç‚¹ï¼ˆç®€åŒ–ï¼‰
        location_pattern = r'\b(Beijing|Shanghai|Guangzhou|Shenzhen)\b'
        locations = re.findall(location_pattern, text)
        for location in locations:
            entities.append({
                'id': f"location_{hash(location)}",
                'name': location,
                'type': 'Location',
                'properties': {'source': 'text_extraction'}
            })

        return entities

    def build_knowledge_from_text(self, texts: List[str]):
        """ä»æ–‡æœ¬åˆ—è¡¨æ„å»ºçŸ¥è¯†å›¾è°±"""
        with self.driver.session() as session:
            for text in texts:
                # æå–å®ä½“
                entities = self.extract_entities_from_text(text)

                # åˆ›å»ºå®ä½“
                for entity in entities:
                    session.run(
                        """
                        MERGE (e:Entity {id: $id})
                        SET e.name = $name,
                            e.type = $type,
                            e.properties = $properties
                        """,
                        **entity
                    )

                # æå–å®ä½“å…³ç³»ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
                words = text.split()
                for i in range(len(words) - 1):
                    word1, word2 = words[i], words[i + 1]
                    if word1.istitle() and word2.istitle():
                        # å¯èƒ½æ˜¯ä¸¤ä¸ªå®ä½“
                        session.run(
                            """
                            MATCH (e1:Entity), (e2:Entity)
                            WHERE e1.name = $name1 AND e2.name = $name2
                            MERGE (e1)-[r:MENTIONED_WITH]->(e2)
                            SET r.context = $context
                            """,
                            name1=word1, name2=word2, context=text
                        )

    def query_knowledge_graph(self, query: str, **params):
        """æŸ¥è¯¢çŸ¥è¯†å›¾è°±"""
        with self.driver.session() as session:
            result = session.run(query, **params)
            return [dict(record) for record in result]

    def get_entity_neighbors(self, entity_id: str, depth: int = 1):
        """è·å–å®ä½“çš„é‚»å±…"""
        query = """
        MATCH (e:Entity {id: $id})-[r*1..$depth]-(neighbor:Entity)
        WHERE e <> neighbor
        RETURN DISTINCT neighbor.name, neighbor.type, labels(neighbor) AS labels
        """
        with self.driver.session() as session:
            result = session.run(query, id=entity_id, depth=depth)
            return [dict(record) for record in result]

    def find_entity_path(self, start_id: str, end_id: str, max_depth: int = 5):
        """æŸ¥æ‰¾å®ä½“é—´çš„è·¯å¾„"""
        query = """
        MATCH path = shortestPath(
            (start:Entity {id: $start})-[*1..$max_depth]-(end:Entity {id: $end})
        )
        RETURN [node in nodes(path) | node.name] AS path_names,
               length(path) AS path_length
        """
        with self.driver.session() as session:
            result = session.run(query, start=start_id, end=end_id, max_depth=max_depth)
            return [dict(record) for record in result]

# ä½¿ç”¨ç¤ºä¾‹
# kg_builder = KnowledgeGraphBuilder(URI, AUTH)
# kg_builder.create_schema()
# kg_builder.import_from_json('knowledge_graph_data.json')
#
# texts = [
#     "Alice works in Beijing and knows Bob.",
#     "Bob lives in Shanghai and is friends with Carol.",
#     "Carol is a researcher specializing in AI."
# ]
# kg_builder.build_knowledge_from_text(texts)
#
# neighbors = kg_builder.get_entity_neighbors('person_123')
# print("å®ä½“é‚»å±…:", neighbors)
```

### 4.3 æ¨èç³»ç»Ÿå®ç°

```python
from neo4j import GraphDatabase
import numpy as np
from typing import List, Dict, Tuple
from collections import defaultdict

class RecommendationEngine:
    """åŸºäº Neo4j çš„æ¨èå¼•æ“"""

    def __init__(self, uri: str, auth: tuple):
        self.driver = GraphDatabase.driver(uri, auth=auth)

    def collaborative_filtering(self, user_id: str, top_n: int = 10):
        """ååŒè¿‡æ»¤æ¨è"""
        query = """
        // æ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ·
        MATCH (u:User {id: $user_id})-[r:RATED]->(i:Item)<-[r2:RATED]-(u2:User)
        WHERE u <> u2
        WITH u2, sum(r.rating * r2.rating) as dot_product,
             sqrt(sum(r.rating^2)) * sqrt(sum(r2.rating^2)) as norm
        WITH u2, dot_product / norm as similarity
        ORDER BY similarity DESC
        LIMIT 50

        // åŸºäºç›¸ä¼¼ç”¨æˆ·çš„è¯„åˆ†æ¨è
        MATCH (u2)-[r2:RATED]->(i:Item)
        WHERE NOT (u)-[:RATED]->(i)
        WITH i, sum(r2.rating * similarity) as weighted_sum,
             sum(similarity) as similarity_sum
        RETURN i.id AS item_id, i.name AS item_name,
               weighted_sum / similarity_sum AS predicted_rating
        ORDER BY predicted_rating DESC
        LIMIT $top_n
        """

        with self.driver.session() as session:
            result = session.run(query, user_id=user_id, top_n=top_n)
            return [dict(record) for record in result]

    def content_based_filtering(self, user_id: str, top_n: int = 10):
        """åŸºäºå†…å®¹çš„æ¨è"""
        query = """
        // è·å–ç”¨æˆ·åå¥½ç‰¹å¾
        MATCH (u:User {id: $user_id})-[r:RATED]->(i:Item)
        WHERE r.rating >= 4  // åªè€ƒè™‘é«˜è¯„åˆ†é¡¹ç›®
        WITH collect(i.features) AS user_features

        // åŸºäºç‰¹å¾ç›¸ä¼¼æ€§æ¨è
        MATCH (i:Item)
        WHERE NOT (u)-[:RATED]->(i)
        WITH i, user_features,
             [f IN user_features WHERE f IN i.features] AS common_features
        WHERE size(common_features) > 0
        WITH i, size(common_features) AS similarity_score,
             common_features
        RETURN i.id AS item_id, i.name AS item_name,
               similarity_score, common_features
        ORDER BY similarity_score DESC, i.popularity DESC
        LIMIT $top_n
        """

        with self.driver.session() as session:
            result = session.run(query, user_id=user_id, top_n=top_n)
            return [dict(record) for record in result]

    def hybrid_recommendation(self, user_id: str, top_n: int = 10, cf_weight: float = 0.6):
        """æ··åˆæ¨èç®—æ³•"""
        # è·å–ååŒè¿‡æ»¤æ¨è
        cf_recs = self.collaborative_filtering(user_id, top_n * 2)

        # è·å–åŸºäºå†…å®¹çš„æ¨è
        cb_recs = self.content_based_filtering(user_id, top_n * 2)

        # åˆå¹¶æ¨èç»“æœ
        combined_scores = defaultdict(float)

        # ååŒè¿‡æ»¤è¯„åˆ†åŠ æƒ
        for rec in cf_recs:
            combined_scores[rec['item_id']] += cf_weight * rec['predicted_rating']

        # åŸºäºå†…å®¹è¯„åˆ†åŠ æƒ
        for rec in cb_recs:
            combined_scores[rec['item_id']] += (1 - cf_weight) * (rec['similarity_score'] / 10)

        # è·å–æœ€ç»ˆæ¨è
        item_ids = sorted(combined_scores.keys(), key=lambda x: combined_scores[x], reverse=True)[:top_n]

        query = """
        UNWIND $item_ids AS item_id
        MATCH (i:Item {id: item_id})
        RETURN i.id, i.name, i.description, i.category
        """

        with self.driver.session() as session:
            result = session.run(query, item_ids=item_ids)
            return [dict(record) for record in result]

    def cold_start_recommendation(self, user_info: Dict, top_n: int = 10):
        """å†·å¯åŠ¨æ¨èï¼ˆé’ˆå¯¹æ–°ç”¨æˆ·ï¼‰"""
        # åŸºäºç”¨æˆ·å±æ€§æ¨èçƒ­é—¨é¡¹ç›®
        query = """
        // åŸºäºç”¨æˆ· demographic æ¨èç›¸åº”ç±»åˆ«çƒ­é—¨é¡¹ç›®
        MATCH (i:Item)
        WHERE i.category IN $categories
        WITH i, i.popularity * 0.7 + i.avg_rating * 0.3 AS score
        RETURN i.id, i.name, i.category, score
        ORDER BY score DESC
        LIMIT $top_n
        """

        with self.driver.session() as session:
            result = session.run(
                query,
                categories=user_info.get('categories', []),
                top_n=top_n
            )
            return [dict(record) for record in result]

    def user_based_recommendation(self, user_id: str, top_n: int = 10):
        """åŸºäºç”¨æˆ·çš„æ¨è"""
        query = """
        // æ‰¾åˆ°æœ€ç›¸ä¼¼çš„ç”¨æˆ·
        MATCH (u:User {id: $user_id})-[r:RATED]->(i:Item)<-[r2:RATED]-(sim_user:User)
        WHERE u <> sim_user
        WITH sim_user,
             gds.similarity.cosine(collect(r.rating), collect(r2.rating)) AS similarity
        ORDER BY similarity DESC
        LIMIT 20

        // è·å–ç›¸ä¼¼ç”¨æˆ·å–œæ¬¢ä½†ç›®æ ‡ç”¨æˆ·æœªè¯„åˆ†çš„é¡¹ç›®
        MATCH (sim_user)-[r:RATED]->(rec:Item)
        WHERE NOT (u)-[:RATED]->(rec)
        WITH rec, avg(r.rating) * similarity AS weighted_score
        RETURN rec.id AS item_id, rec.name AS item_name, rec.category,
               weighted_score
        ORDER BY weighted_score DESC
        LIMIT $top_n
        """

        with self.driver.session() as session:
            result = session.run(query, user_id=user_id, top_n=top_n)
            return [dict(record) for record in result]

    def item_based_recommendation(self, user_id: str, top_n: int = 10):
        """åŸºäºç‰©å“çš„æ¨è"""
        query = """
        // è·å–ç”¨æˆ·å–œæ¬¢çš„é¡¹ç›®
        MATCH (u:User {id: $user_id})-[r:RATED]->(liked:Item)
        WHERE r.rating >= 4
        COLLECT liked AS liked_items

        // æ‰¾åˆ°ä¸å–œæ¬¢çš„é¡¹ç›®ç›¸ä¼¼çš„é¡¹ç›®
        UNWIND liked_items AS liked_item
        MATCH (liked_item)<-[r:SIMILAR_TO]-(similar_item:Item)
        WHERE NOT (u)-[:RATED]->(similar_item)
        WITH similar_item, sum(r.similarity) as total_similarity,
               avg(similar_item.avg_rating) as avg_rating
        RETURN similar_item.id AS item_id, similar_item.name AS item_name,
               total_similarity, avg_rating
        ORDER BY total_similarity DESC, avg_rating DESC
        LIMIT $top_n
        """

        with self.driver.session() as session:
            result = session.run(query, user_id=user_id, top_n=top_n)
            return [dict(record) for record in result]

    def explain_recommendation(self, user_id: str, item_id: str):
        """è§£é‡Šæ¨èåŸå› """
        query = """
        // æ‰¾å‡ºæ¨èåŸå› 
        MATCH (u:User {id: $user_id})-[r:RATED]->(pref:Item)
        MATCH (pref)-[s:SIMILAR_TO]->(rec:Item {id: $item_id})
        WHERE r.rating >= 4
        RETURN 'ä½ å–œæ¬¢çš„' + pref.name + 'ä¸' + rec.name + 'ç›¸ä¼¼' AS reason,
               s.similarity AS confidence

        UNION

        // æ‰¾å‡ºå…±åŒå–œæ¬¢çš„ç”¨æˆ·
        MATCH (u:User {id: $user_id})-[r1:RATED]->(i:Item)<-[r2:RATED]-(similar:User)
        MATCH (similar)-[r3:RATED]->(rec:Item {id: $item_id})
        WHERE r1.rating >= 4 AND r3.rating >= 4
        RETURN 'å’Œä½ å–œå¥½ç›¸ä¼¼çš„ç”¨æˆ·ä¹Ÿå–œæ¬¢è¿™ä¸ª' AS reason,
               0.8 AS confidence

        UNION

        // åŸºäºå†…å®¹ç‰¹å¾
        MATCH (u:User {id: $user_id})-[r:RATED]->(pref:Item)
        WHERE r.rating >= 4
        MATCH (rec:Item {id: $item_id})
        WHERE pref.category = rec.category
        RETURN 'ä½ å–œæ¬¢' + pref.category + 'ç±»åˆ«çš„é¡¹ç›®' AS reason,
               0.6 AS confidence
        """

        with self.driver.session() as session:
            result = session.run(query, user_id=user_id, item_id=item_id)
            return [dict(record) for record in result]

    def evaluate_recommendations(self, user_id: str, test_size: int = 20):
        """è¯„ä¼°æ¨èç³»ç»Ÿæ€§èƒ½"""
        # è·å–æµ‹è¯•æ•°æ®
        query = """
        MATCH (u:User {id: $user_id})-[r:RATED]->(i:Item)
        RETURN i.id, r.rating
        ORDER BY r.timestamp DESC
        SKIP $skip LIMIT $limit
        """

        with self.driver.session() as session:
            # è·å–æµ‹è¯•é›†
            test_result = session.run(query, user_id=user_id, skip=0, limit=test_size)
            test_data = [(record['i.id'], record['r.rating']) for record in test_result]

            # è·å–è®­ç»ƒé›†
            train_result = session.run(query, user_id=user_id, skip=test_size, limit=100)
            train_data = [(record['i.id'], record['r.rating']) for record in train_result]

            # è·å–æ¨è
            recommendations = self.collaborative_filtering(user_id, test_size)
            recommended_items = [rec['item_id'] for rec in recommendations]

            # è®¡ç®—æŒ‡æ ‡
            test_items = [item_id for item_id, rating in test_data if rating >= 4]

            # Precision@K
            precision = len(set(test_items) & set(recommended_items)) / len(recommended_items)

            # Recall@K
            recall = len(set(test_items) & set(recommended_items)) / len(test_items)

            # F1 Score
            f1 = 2 * (precision * recall) / (precision + recall)

            return {
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'recommended_count': len(recommended_items),
                'relevant_count': len(test_items)
            }

# ä½¿ç”¨ç¤ºä¾‹
# recommender = RecommendationEngine(URI, AUTH)
#
# # ååŒè¿‡æ»¤æ¨è
# cf_recs = recommender.collaborative_filtering('user1')
# print("ååŒè¿‡æ»¤æ¨è:", cf_recs)
#
# # æ··åˆæ¨è
# hybrid_recs = recommender.hybrid_recommendation('user1')
# print("æ··åˆæ¨è:", hybrid_recs)
#
# # æ¨èè§£é‡Š
# explanation = recommender.explain_recommendation('user1', 'item123')
# print("æ¨èåŸå› :", explanation)
#
# # è¯„ä¼°æ€§èƒ½
# metrics = recommender.evaluate_recommendations('user1')
# print("è¯„ä¼°æŒ‡æ ‡:", metrics)
```

---

## 5. æ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ

### 5.1 ç´¢å¼•ä¼˜åŒ–

```python
class IndexManager:
    """ç´¢å¼•ç®¡ç†å™¨"""

    def __init__(self, driver):
        self.driver = driver

    def create_optimal_indexes(self):
        """åˆ›å»ºæœ€ä¼˜ç´¢å¼•"""
        indexes = [
            # å•å±æ€§ç´¢å¼•
            "CREATE INDEX user_email_index IF NOT EXISTS FOR (u:User) ON (u.email)",
            "CREATE INDEX product_category_index IF NOT EXISTS FOR (p:Product) ON (p.category)",
            "CREATE INDEX post_timestamp_index IF NOT EXISTS FOR (p:Post) ON (p.timestamp)",

            # å¤åˆç´¢å¼•
            "CREATE INDEX user_city_age_index IF NOT EXISTS FOR (u:User) ON (u.city, u.age)",
            "CREATE INDEX product_category_price_index IF NOT EXISTS FOR (p:Product) ON (p.category, p.price)",

            # æ–‡æœ¬ç´¢å¼•ï¼ˆNeo4j 5.x+ï¼‰
            "CREATE FULLTEXT INDEX product_name_index IF NOT EXISTS FOR (p:Product) ON EACH [p.name, p.description]",
            "CREATE FULLTEXT INDEX post_content_index IF NOT EXISTS FOR (p:Post) ON EACH [p.title, p.content]",
        ]

        with self.driver.session() as session:
            for idx_query in indexes:
                try:
                    result = session.run(idx_query)
                    print(f"ç´¢å¼•åˆ›å»ºæˆåŠŸ: {result.consume().query}")
                except Exception as e:
                    print(f"ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")

    def analyze_index_usage(self):
        """åˆ†æç´¢å¼•ä½¿ç”¨æƒ…å†µ"""
        query = """
        CALL db.indexes()
        YIELD name, state, type, entityType, properties
        RETURN name, state, type, entityType, properties
        """

        with self.driver.session() as session:
            result = session.run(query)
            print("å½“å‰ç´¢å¼•:")
            for record in result:
                print(f"  {record['name']}")
                print(f"    çŠ¶æ€: {record['state']}")
                print(f"    ç±»å‹: {record['type']}")
                print(f"    æ ‡ç­¾: {record['entityType']}")
                print(f"    å±æ€§: {record['properties']}")

    def suggest_missing_indexes(self):
        """å»ºè®®ç¼ºå¤±çš„ç´¢å¼•"""
        # æŸ¥è¯¢åˆ†æå™¨ä¼šå»ºè®®åˆ›å»ºç´¢å¼•çš„æŸ¥è¯¢
        query = """
        CALL db.queryPlan.explain(
            'MATCH (p:Person) WHERE p.name = $name RETURN p'
        )
        YIELD plan
        RETURN plan
        """

        with self.driver.session() as session:
            result = session.run(query)
            for record in result:
                print("æŸ¥è¯¢è®¡åˆ’:", record)
```

### 5.2 æŸ¥è¯¢ä¼˜åŒ–æŠ€å·§

```python
class QueryOptimizer:
    """æŸ¥è¯¢ä¼˜åŒ–å™¨"""

    def __init__(self, driver):
        self.driver = driver

    def optimize_query_examples(self):
        """æŸ¥è¯¢ä¼˜åŒ–ç¤ºä¾‹"""

        # 1. é¿å…ç¬›å¡å°”ç§¯
        bad_query = """
        MATCH (a:Person), (b:Person)
        WHERE a.city = b.city AND a <> b
        """

        good_query = """
        MATCH (a:Person)
        MATCH (b:Person)
        WHERE a.city = b.city AND a <> b
        """

        # 2. ä½¿ç”¨ EXISTS ä»£æ›¿ OPTIONAL MATCH
        bad_query = """
        MATCH (p:Person)
        OPTIONAL MATCH (p)-[:HAS_EMAIL]->()
        WHERE p.email IS NOT NULL
        """

        good_query = """
        MATCH (p:Person)
        WHERE EXISTS((p)-[:HAS_EMAIL]->())
        """

        # 3. ä½¿ç”¨ LIMIT é™åˆ¶ç»“æœ
        optimized_query = """
        MATCH (p:Person)
        WHERE p.age > $age
        RETURN p.name, p.age
        LIMIT $limit
        """

        with self.driver.session() as session:
            result = session.run(optimized_query, age=25, limit=100)
            print("ä¼˜åŒ–æŸ¥è¯¢ç»“æœ:", len(list(result)))

    def batch_operation_strategies(self):
        """æ‰¹é‡æ“ä½œç­–ç•¥"""

        # 1. ä½¿ç”¨ UNWIND è¿›è¡Œæ‰¹é‡æ’å…¥
        batch_insert = """
        UNWIND $batch AS data
        CREATE (n:Node {
            id: data.id,
            name: data.name,
            properties: data.properties
        })
        """

        # 2. ä½¿ç”¨ PERIODIC COMMIT å¤„ç†å¤§é‡æ•°æ®
        periodic_commit = """
        USING PERIODIC COMMIT 1000
        LOAD CSV WITH HEADERS FROM 'file:///large_data.csv' AS row
        CREATE (n:Node {id: row.id, name: row.name})
        """

        # 3. ä½¿ç”¨ apoc.periodic.iterate æ‰¹é‡æ›´æ–°
        batch_update = """
        CALL apoc.periodic.iterate(
          'MATCH (n:Node) WHERE n.status = "pending" RETURN n',
          'SET n.processed = true, n.timestamp = timestamp()',
          {batchSize:1000, parallel:true}
        )
        """

        return batch_insert, periodic_commit, batch_update

    def memory_efficient_processing(self):
        """å†…å­˜é«˜æ•ˆå¤„ç†"""

        # 1. æµå¼å¤„ç†å¤§æ•°æ®é›†
        def process_large_dataset():
            with self.driver.session() as session:
                result = session.run("MATCH (n:LargeNode) RETURN n.id")

                batch_size = 1000
                batch = []

                for record in result:
                    batch.append(record['n.id'])
                    if len(batch) >= batch_size:
                        # å¤„ç†æ‰¹æ¬¡
                        self.process_batch(batch)
                        batch = []

                # å¤„ç†æœ€åä¸€æ‰¹
                if batch:
                    self.process_batch(batch)

        # 2. ä½¿ç”¨ SKIP å’Œ LIMIT å®ç°åˆ†é¡µ
        def paginated_query(page: int, page_size: int):
            query = """
            MATCH (n:Node)
            RETURN n
            ORDER BY n.id
            SKIP $skip LIMIT $limit
            """
            with self.driver.session() as session:
                return session.run(
                    query,
                    skip=page * page_size,
                    limit=page_size
                )

        return process_large_dataset, paginated_query
```

### 5.3 ç›‘æ§å’Œè¯Šæ–­

```python
import time
from contextlib import contextmanager
from neo4j import GraphDatabase, Query, Result

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self, driver):
        self.driver = driver
        self.query_times = []

    @contextmanager
    def monitor_query(self, query: str):
        """ç›‘æ§æŸ¥è¯¢æ‰§è¡Œæ—¶é—´"""
        start_time = time.time()
        try:
            with self.driver.session() as session:
                result = session.run(query)
                yield result
        finally:
            end_time = time.time()
            execution_time = end_time - start_time
            self.query_times.append({
                'query': query[:100] + '...' if len(query) > 100 else query,
                'time': execution_time,
                'timestamp': time.time()
            })

    def get_slow_queries(self, threshold: float = 1.0):
        """è·å–æ…¢æŸ¥è¯¢"""
        return [q for q in self.query_times if q['time'] > threshold]

    def analyze_query_performance(self):
        """åˆ†ææŸ¥è¯¢æ€§èƒ½"""
        if not self.query_times:
            return None

        times = [q['time'] for q in self.query_times]
        return {
            'total_queries': len(times),
            'avg_time': sum(times) / len(times),
            'min_time': min(times),
            'max_time': max(times),
            'total_time': sum(times)
        }

    def profile_query(self, query: str, **params):
        """åˆ†ææŸ¥è¯¢æ€§èƒ½"""
        with self.driver.session() as session:
            # ä½¿ç”¨ PROFILE è·å–è¯¦ç»†æ€§èƒ½ä¿¡æ¯
            profile_result = session.run(f"PROFILE {query}", **params)

            # ä½¿ç”¨ EXPLAIN è·å–æ‰§è¡Œè®¡åˆ’
            explain_result = session.run(f"EXPLAIN {query}", **params)

            return {
                'profile': [dict(r) for r in profile_result],
                'explain': [dict(r) for r in explain_result]
            }

class Neo4jHealthChecker:
    """Neo4j å¥åº·æ£€æŸ¥å™¨"""

    def __init__(self, driver):
        self.driver = driver

    def check_connection(self):
        """æ£€æŸ¥è¿æ¥"""
        try:
            with self.driver.session() as session:
                result = session.run("RETURN 1")
                return result.single()[0] == 1
        except:
            return False

    def get_database_info(self):
        """è·å–æ•°æ®åº“ä¿¡æ¯"""
        with self.driver.session() as session:
            # æ•°æ®åº“ç‰ˆæœ¬
            version = session.run("CALL dbms.components() YIELD versions RETURN versions[0] as version")

            # èŠ‚ç‚¹ç»Ÿè®¡
            nodes = session.run("MATCH (n) RETURN count(n) as count")

            # å…³ç³»ç»Ÿè®¡
            relationships = session.run("MATCH ()-[r]-() RETURN count(r) as count")

            return {
                'version': version.single()['version'],
                'node_count': nodes.single()['count'],
                'relationship_count': relationships.single()['count']
            }

    def check_indexes_health(self):
        """æ£€æŸ¥ç´¢å¼•å¥åº·çŠ¶æ€"""
        with self.driver.session() as session:
            result = session.run("SHOW INDEXES YIELD name, state, type RETURN name, state, type")
            return [dict(r) for r in result]

    def check_memory_usage(self):
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨"""
        with self.driver.session() as session:
            # è·å– JVM å†…å­˜ä¿¡æ¯ï¼ˆéœ€è¦ç®¡ç†å‘˜æƒé™ï¼‰
            try:
                result = session.run("CALL dbms.queryJmx('java.lang:type=Memory') RETURN HeapMemoryUsage")
                return [dict(r) for r in result]
            except:
                return {"error": "éœ€è¦ç®¡ç†å‘˜æƒé™"}

    def full_health_check(self):
        """å®Œæ•´å¥åº·æ£€æŸ¥"""
        health_status = {
            'connection': self.check_connection(),
            'database_info': self.get_database_info(),
            'indexes': self.check_indexes_health(),
            'memory': self.check_memory_usage()
        }

        health_status['overall_status'] = (
            'healthy' if health_status['connection'] and
            health_status['database_info']['node_count'] > 0 else 'unhealthy'
        )

        return health_status

# ä½¿ç”¨ç¤ºä¾‹
# monitor = PerformanceMonitor(driver)
#
# with monitor.monitor_query("MATCH (n:Person) RETURN count(n)") as result:
#     print(result.single())
#
# slow_queries = monitor.get_slow_queries(threshold=0.5)
# print("æ…¢æŸ¥è¯¢:", slow_queries)
#
# performance_stats = monitor.analyze_query_performance()
# print("æ€§èƒ½ç»Ÿè®¡:", performance_stats)
#
# health_checker = Neo4jHealthChecker(driver)
# health = health_checker.full_health_check()
# print("å¥åº·æ£€æŸ¥:", health)
```

### 5.4 ç¼“å­˜ç­–ç•¥

```python
from functools import lru_cache
import hashlib
import json

class Neo4jCache:
    """Neo4j æŸ¥è¯¢ç¼“å­˜"""

    def __init__(self, driver, cache_size=128):
        self.driver = driver
        self.cache = {}
        self.cache_size = cache_size

    def _cache_key(self, query: str, params: Dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_data = {
            'query': query,
            'params': sorted(params.items())
        }
        return hashlib.md5(json.dumps(key_data, sort_keys=True).encode()).hexdigest()

    def execute_cached_query(self, query: str, params: Dict = None, ttl: int = 3600):
        """æ‰§è¡Œç¼“å­˜æŸ¥è¯¢"""
        cache_key = self._cache_key(query, params or {})

        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.cache:
            cached_data = self.cache[cache_key]
            if time.time() - cached_data['timestamp'] < cached_data['ttl']:
                return cached_data['result']

        # æ‰§è¡ŒæŸ¥è¯¢
        with self.driver.session() as session:
            result = session.run(query, **(params or {}))
            data = [dict(record) for record in result]

        # å­˜å‚¨åˆ°ç¼“å­˜
        if len(self.cache) >= self.cache_size:
            # ç§»é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
            oldest_key = min(self.cache.keys(), key=lambda k: self.cache[k]['timestamp'])
            del self.cache[oldest_key]

        self.cache[cache_key] = {
            'result': data,
            'timestamp': time.time(),
            'ttl': ttl
        }

        return data

    def clear_cache(self):
        """æ¸…é™¤ç¼“å­˜"""
        self.cache.clear()

    def get_cache_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total_items = len(self.cache)
        expired_items = sum(
            1 for item in self.cache.values()
            if time.time() - item['timestamp'] > item['ttl']
        )

        return {
            'total_items': total_items,
            'expired_items': expired_items,
            'hit_rate': getattr(self, '_hits', 0) / (getattr(self, '_hits', 0) + getattr(self, '_misses', 0))
        }

# ä½¿ç”¨ç¼“å­˜è£…é¥°å™¨
def cached_neo4j_query(ttl: int = 3600):
    """Neo4j æŸ¥è¯¢ç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        @lru_cache(maxsize=128)
        def wrapper(*args, **kwargs):
            # è¿™é‡Œåº”è¯¥åŒ…å«å®é™…çš„æŸ¥è¯¢é€»è¾‘
            result = func(*args, **kwargs)
            return result
        return wrapper
    return decorator

# Redis ç¼“å­˜é›†æˆç¤ºä¾‹
class RedisNeo4jCache:
    """Redis ç¼“å­˜çš„ Neo4j æŸ¥è¯¢"""

    def __init__(self, driver, redis_client):
        self.driver = driver
        self.redis = redis_client

    def execute_with_redis_cache(self, query: str, params: Dict = None, ttl: int = 3600):
        """ä½¿ç”¨ Redis ç¼“å­˜çš„æŸ¥è¯¢"""
        cache_key = self._generate_cache_key(query, params or {})

        # å°è¯•ä» Redis è·å–
        cached_result = self.redis.get(cache_key)
        if cached_result:
            return json.loads(cached_result)

        # æ‰§è¡ŒæŸ¥è¯¢
        with self.driver.session() as session:
            result = session.run(query, **(params or {}))
            data = [dict(record) for record in result]

        # å­˜å‚¨åˆ° Redis
        self.redis.setex(cache_key, ttl, json.dumps(data))

        return data
```

### 5.5 æœ€ä½³å®è·µæ€»ç»“

```python
# Neo4j æœ€ä½³å®è·µæ€»ç»“
BEST_PRACTICES = {
    "æ•°æ®å»ºæ¨¡": [
        "ä¸ºé¢‘ç¹æŸ¥è¯¢çš„å±æ€§åˆ›å»ºç´¢å¼•",
        "ä½¿ç”¨åˆé€‚çš„æ ‡ç­¾ç»„ç»‡æ•°æ®",
        "é¿å…è¿‡æ·±çš„èŠ‚ç‚¹åµŒå¥—",
        "åˆç†ä½¿ç”¨å…³ç³»ç±»å‹"
    ],

    "æŸ¥è¯¢ä¼˜åŒ–": [
        "ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢é˜²æ­¢æ³¨å…¥",
        "é¿å…ç¬›å¡å°”ç§¯",
        "ä½¿ç”¨ LIMIT é™åˆ¶ç»“æœé›†",
        "åˆç†ä½¿ç”¨ OPTIONAL MATCH å’Œ EXISTS",
        "æ‰¹é‡æ“ä½œä½¿ç”¨ UNWIND"
    ],

    "æ€§èƒ½ä¼˜åŒ–": [
        "ç›‘æ§æ…¢æŸ¥è¯¢",
        "ä½¿ç”¨è¿æ¥æ± ",
        "åˆç†è®¾ç½®äº‹åŠ¡è¾¹ç•Œ",
        "ä½¿ç”¨æ‰¹é‡æ“ä½œ",
        "å®šæœŸæ¸…ç†ä¸éœ€è¦çš„æ•°æ®"
    ],

    "å¼€å‘å®è·µ": [
        "ä½¿ç”¨è¿æ¥ç®¡ç†å™¨",
        "å®ç°é‡è¯•æœºåˆ¶",
        "æ·»åŠ é€‚å½“çš„é”™è¯¯å¤„ç†",
        "è®°å½•æŸ¥è¯¢æ—¥å¿—",
        "ä½¿ç”¨å•å…ƒæµ‹è¯•éªŒè¯æŸ¥è¯¢"
    ],

    "è¿ç»´ç®¡ç†": [
        "å®šæœŸå¤‡ä»½æ•°æ®",
        "ç›‘æ§æ•°æ®åº“å¥åº·çŠ¶æ€",
        "åŠæ—¶æ›´æ–°åˆ°ç¨³å®šç‰ˆæœ¬",
        "é…ç½®é€‚å½“çš„å†…å­˜è®¾ç½®",
        "å¯ç”¨æŸ¥è¯¢æ—¥å¿—"
    ]
}

# é”™è¯¯å¤„ç†æœ€ä½³å®è·µ
class Neo4jErrorHandler:
    """Neo4j é”™è¯¯å¤„ç†"""

    def __init__(self, driver):
        self.driver = driver

    def safe_execute_query(self, query: str, params: Dict = None, max_retries: int = 3):
        """å®‰å…¨æ‰§è¡ŒæŸ¥è¯¢ï¼ˆå¸¦é‡è¯•ï¼‰"""
        from neo4j.exceptions import ServiceUnavailable, TransientError

        for attempt in range(max_retries):
            try:
                with self.driver.session() as session:
                    result = session.run(query, **(params or {}))
                    return [dict(record) for record in result]
            except (ServiceUnavailable, TransientError) as e:
                if attempt == max_retries - 1:
                    raise
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            except Exception as e:
                # è®°å½•é”™è¯¯
                self.log_error(query, params, e)
                raise

    def log_error(self, query: str, params: Dict, error: Exception):
        """è®°å½•é”™è¯¯æ—¥å¿—"""
        error_log = {
            'timestamp': time.time(),
            'query': query,
            'params': params,
            'error': str(error),
            'error_type': type(error).__name__
        }

        # è¿™é‡Œå¯ä»¥é›†æˆæ—¥å¿—ç³»ç»Ÿ
        print(f"Neo4j Error: {error_log}")

        # æˆ–è€…å†™å…¥æ—¥å¿—æ–‡ä»¶
        import logging
        logging.error("Neo4j query failed", exc_info=True, extra=error_log)
```

---

## æ€»ç»“

æœ¬æ•™ç¨‹æ¶µç›–äº† Neo4j å’Œ Python æ•´åˆçš„æ–¹æ–¹é¢é¢ï¼š

1. **åŸºç¡€æ¦‚å¿µ**ï¼šç†è§£å›¾æ•°æ®åº“çš„æ ¸å¿ƒæ¦‚å¿µå’Œæ•°æ®æ¨¡å‹
2. **Cypher è¯­è¨€**ï¼šæŒæ¡ä»åŸºç¡€åˆ°é«˜çº§çš„æ‰€æœ‰æŸ¥è¯¢è¯­æ³•
3. **Python æ•´åˆ**ï¼šå­¦ä¹ å„ç§è¿æ¥æ–¹å¼ã€ä¼šè¯ç®¡ç†å’Œäº‹åŠ¡å¤„ç†
4. **å®æˆ˜æ¡ˆä¾‹**ï¼šé€šè¿‡ç¤¾äº¤ç½‘ç»œã€çŸ¥è¯†å›¾è°±å’Œæ¨èç³»ç»Ÿç­‰æ¡ˆä¾‹æ·±å…¥ç†è§£
5. **æ€§èƒ½ä¼˜åŒ–**ï¼šæŒæ¡ç´¢å¼•ä¼˜åŒ–ã€æŸ¥è¯¢ä¼˜åŒ–ã€ç¼“å­˜ç­–ç•¥ç­‰æœ€ä½³å®è·µ

### å­¦ä¹ å»ºè®®

1. **å¾ªåºæ¸è¿›**ï¼šä»åŸºç¡€æ¦‚å¿µå¼€å§‹ï¼Œé€æ­¥æ·±å…¥åˆ°é«˜çº§åŠŸèƒ½
2. **å®è·µä¸ºä¸»**ï¼šå¤šåŠ¨æ‰‹å†™ä»£ç ï¼Œå°è¯•ä¸åŒçš„æŸ¥è¯¢å’Œæ“ä½œ
3. **æ€§èƒ½æ„è¯†**ï¼šå§‹ç»ˆè€ƒè™‘æŸ¥è¯¢æ€§èƒ½å’Œæ•°æ®æ¨¡å‹è®¾è®¡
4. **æŒç»­å­¦ä¹ **ï¼šå…³æ³¨ Neo4j æ–°ç‰ˆæœ¬ç‰¹æ€§å’Œæœ€ä½³å®è·µæ›´æ–°

### è¿›é˜¶æ–¹å‘

- æ·±å…¥å­¦ä¹ å›¾ç®—æ³•ï¼ˆPageRankã€ç¤¾åŒºæ£€æµ‹ã€è·¯å¾„ç®—æ³•ç­‰ï¼‰
- æŒæ¡ Neo4j çš„é«˜çº§ç‰¹æ€§ï¼ˆAPOC æ’ä»¶ã€å›¾æ•°æ®ç§‘å­¦åº“ç­‰ï¼‰
- å­¦ä¹ åˆ†å¸ƒå¼å›¾æ•°æ®åº“å’Œå¤§æ•°æ®å¤„ç†
- æ¢ç´¢ Neo4j åœ¨ç‰¹å®šé¢†åŸŸçš„åº”ç”¨ï¼ˆé‡‘èã€åŒ»ç–—ã€ç¤¾äº¤ç½‘ç»œç­‰ï¼‰

å¸Œæœ›è¿™ä¸ªæ•™ç¨‹èƒ½å¸®åŠ©ä½ æˆä¸º Neo4j ä¸“å®¶ï¼